scala> import org.apache.spark.sql.types._
scala> val schema = StructType(StructField("Date",StringType)::StructField("Time",StringType)::StructField("City",StringType)::StructField("Product",StringType)::StructField("Sales",DoubleType)::StructField("Paymode",StringType)::Nil)
scala> val file = spark.read.format("csv").option("header",false).option("delimiter","\t").schema(schema).load("/media/dell/HDD_VOL1/DataSource/RetailDataAnalysis/Retail_Sample_Data_Set.txt")
file: org.apache.spark.sql.DataFrame = [Date: string, Time: string ... 4 more fields]
scala> file.createOrReplaceTempView("RDA")
scala> spark.sql("select * from RDA limit 5").show
+----------+-----+----------+-------------------+------+----------+
|      Date| Time|      City|            Product| Sales|   Paymode|
+----------+-----+----------+-------------------+------+----------+
|2012-01-01|09:00|  San Jose|     Men's Clothing|214.05|      Amex|
|2012-01-01|09:00|Fort Worth|   Women's Clothing|153.57|      Visa|
|2012-01-01|09:00| San Diego|              Music| 66.08|      Cash|
|2012-01-01|09:00|Pittsburgh|       Pet Supplies|493.51|  Discover|
|2012-01-01|09:00|     Omaha|Children's Clothing|235.63|MasterCard|
+----------+-----+----------+-------------------+------+----------+



1. Calculate sales breakdown by product category across all of the stores.
SOLUTION:
scala> spark.sql("select sum(sales),Product,City from RDA group by Product,City order by City").write.format("csv").save("/media/dell/HDD_VOL1/DataOut/RetailDataAnalysis/Q1/")

2. Calculate sales breakdown by store across all of the stores. Assume there is one store per city.
SOLUTION:
scala> spark.sql("select sum(sales),City from RDA group by City order by City").write.format("csv").save("/media/dell/HDD_VOL1/DataOut/RetailDataAnalysis/Q2")

3. Find the total sales values across all the stores and the total number of sales.
SOLUTION:
scala> spark.sql("select sum(sales) from RDA").show
+-----------------+
|       sum(sales)|
+-----------------+
|49585.37000000002|
+-----------------+
