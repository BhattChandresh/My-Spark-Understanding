## foreach and foreachPartition Examples
scala> val r1 = spark.sparkContext.parallelize(Array(1,2,3,4,5,6,7,8,9),3)
r1: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[2] at parallelize at <console>:23

scala> val t1 = r1.map(x => x*x)
t1: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[3] at map at <console>:25

scala> t1.foreach(println)
1
4
9
49
64
81
16
25
36

scala> t1.foreachPartition
foreachPartition   foreachPartitionAsync

scala> t1.foreachPartition(x => println(x.max))
36
9
81
