## Explode
scala> val test = spark.read.json(sc.parallelize(Seq("""{"a":1,"b":[2,3]}""")))
warning: there was one deprecation warning (since 2.2.0); for details, enable `:setting -deprecation' or `:replay -deprecation'
test: org.apache.spark.sql.DataFrame = [a: bigint, b: array<bigint>]

scala> test.printSchema
root
 |-- a: long (nullable = true)
 |-- b: array (nullable = true)
 |    |-- element: long (containsNull = true)

scala> val flatten = test.withColumn("b",explode($"b"))
flatten: org.apache.spark.sql.DataFrame = [a: bigint, b: bigint]

scala> flatten.show
+---+---+
|  a|  b|
+---+---+
|  1|  2|
|  1|  3|
+---+---+


## flatMap
scala> val ds = Seq((0, "Lorem ipsum dolor", 1.0, Array("prp1", "prp2", "prp3"))).toDF("id","text","value","properties")
     .toDF("id","text","value","properties")
     .as[(Integer,String,Double,scala.List[String])]
ds: org.apache.spark.sql.Dataset[(Integer, String, Double, List[String])] = [id: int, text: string ... 2 more fields]

scala> ds.flatMap { t => t._4.map { prp => (t._1,t._2,t._3,prp)}}.show
+---+-----------------+---+----+
| _1|               _2| _3|  _4|
+---+-----------------+---+----+
|  0|Lorem ipsum dolor|1.0|prp1|
|  0|Lorem ipsum dolor|1.0|prp2|
|  0|Lorem ipsum dolor|1.0|prp3|
+---+-----------------+---+----+
